# INFO1185-Proyecto3-SqueezeNet

Transfer Learning para ClasificaciÃ³n de Vegetales utilizando **SqueezeNet 1.1** preentrenado en ImageNet.

**Autores:** Benja Espinoza y Pablo Antivil  
**Curso:** INFO1185 - Inteligencia Artificial III  
**AÃ±o:** 2025

---

## ğŸ¯ Objetivo

Implementar y comparar **tres variantes de clasificadores** usando transfer learning con SqueezeNet:
- **VersiÃ³n 1 (Simple)**: Arquitectura bÃ¡sica sin regularizaciÃ³n
- **VersiÃ³n 2A (Extendido)**: 4 capas FC sin BatchNorm/Dropout
- **VersiÃ³n 2B (Regularizado)**: 4 capas FC con BatchNorm y Dropout (p=0.3)

---

## ğŸ† Resultados Obtenidos

| Modelo | Test Accuracy | Val Accuracy | Ã‰pocas | ParÃ¡metros Entrenables |
|--------|--------------|--------------|--------|----------------------|
| **V1 (Simple)** | **98.00%** ğŸ† | 97.87% | 14 | 265,221 |
| **V2A (Sin Reg.)** | 92.00% | 95.74% | 12 | 427,525 |
| **V2B (Con Reg.)** | 94.00% | 97.87% | 19 | 428,293 |

**Hallazgo principal:** El modelo mÃ¡s simple (V1) superÃ³ a los complejos, demostrando que con Transfer Learning y datasets pequeÃ±os (438 samples), arquitecturas simples pueden ser Ã³ptimas.

---

## ğŸ¥• Dataset

**5 Clases:**
- JalapeÃ±o (jalepeno)
- Chili Pepper
- Carrot
- Corn
- Cucumber

**Estructura:**
```
archive/
â”œâ”€â”€ train/          (438 imÃ¡genes de las 5 clases)
â”œâ”€â”€ validation/     (47 imÃ¡genes)
â””â”€â”€ test/           (50 imÃ¡genes)
```

---

## ğŸ“ Estructura del Proyecto

```
INFO1185-Proyecto3-SqueezeNet/
â”œâ”€â”€ SqueezeNet_Transfer_Learning.ipynb  # Notebook principal (Jupyter/Colab)
â”œâ”€â”€ archive/                            # Dataset (no versionado)
â”‚   â”œâ”€â”€ train/          (438 imÃ¡genes de las 5 clases)
â”‚   â”œâ”€â”€ validation/     (47 imÃ¡genes)
â”‚   â””â”€â”€ test/           (50 imÃ¡genes)
â”œâ”€â”€ squeezenet_modelo_final.pth         # Modelo V1 guardado
â”œâ”€â”€ squeezenet_version_2a.pth           # Modelo V2A guardado
â”œâ”€â”€ squeezenet_version_2b.pth           # Modelo V2B guardado
â”œâ”€â”€ requirements.txt                    # Dependencias de Python
â”œâ”€â”€ .gitignore                          # Archivos ignorados por Git
â””â”€â”€ README.md                           # DocumentaciÃ³n
```

**Nota:** El proyecto fue migrado a un Ãºnico notebook de Jupyter para facilitar su ejecuciÃ³n en Google Colab.

---

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### OpciÃ³n 1: Google Colab (Recomendado)

1. Abrir `SqueezeNet_Transfer_Learning.ipynb` en Google Colab
2. Subir el dataset a Google Drive o usar Kaggle API
3. Ejecutar todas las celdas en orden

### OpciÃ³n 2: Entorno Local

```bash
# 1. Clonar repositorio
git clone https://github.com/pabloantivil/INFO1185-Proyecto3-SqueezeNet.git
cd INFO1185-Proyecto3-SqueezeNet

# 2. Crear entorno virtual (opcional pero recomendado)
python -m venv venv
# Windows:
.\venv\Scripts\Activate.ps1
# Linux/Mac:
source venv/bin/activate

# 3. Instalar PyTorch (CPU o GPU segÃºn disponibilidad)
# CPU:
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
# GPU (CUDA 11.8):
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# 4. Instalar otras dependencias
pip install -r requirements.txt

# 5. Abrir Jupyter Notebook
jupyter notebook SqueezeNet_Transfer_Learning.ipynb
```

---

## âœ… Estado del Proyecto

### Tareas Completadas
- âœ… PreparaciÃ³n de datos (train/val/test)
- âœ… Data augmentation y normalizaciÃ³n ImageNet
- âœ… DataLoaders optimizados (batch_size=32)
- âœ… SqueezeNet 1.1 preentrenado (feature extractor congelado)
- âœ… ImplementaciÃ³n de 3 clasificadores personalizados (V1, V2A, V2B)
- âœ… Loop de entrenamiento con Early Stopping
- âœ… ValidaciÃ³n y cÃ¡lculo de mÃ©tricas (Accuracy, Loss)
- âœ… EvaluaciÃ³n en test set
- âœ… Guardado de modelos (.pth)
- âœ… AnÃ¡lisis comparativo de resultados

### Resultados Finales
- **V1 (Simple):** 98% Test Accuracy (mejor desempeÃ±o)
- **V2A (Sin regularizaciÃ³n):** 92% Test Accuracy
- **V2B (Con regularizaciÃ³n):** 94% Test Accuracy (+2% mejora sobre V2A)

**ConclusiÃ³n:** Transfer Learning con SqueezeNet demostrÃ³ excelente generalizaciÃ³n. El modelo simple (V1) superÃ³ arquitecturas complejas debido al tamaÃ±o reducido del dataset (438 muestras) y la calidad de las features preentrenadas.

---

## ğŸ§  InformaciÃ³n del Modelo

### SqueezeNet 1.1 - Transfer Learning

**Arquitectura Base:**
- **ParÃ¡metros totales:** ~1.2M (modelo completo)
- **ParÃ¡metros congelados:** ~0.7M (feature extractor)
- **Extractor de caracterÃ­sticas:** 512 features
- **Componentes clave:** Fire Modules (squeeze + expand layers)
- **Pretrained:** ImageNet (1000 clases)

**Clasificadores Personalizados:**

1. **VersiÃ³n 1 (Simple):**
   - Linear(512 â†’ 5)
   - **ParÃ¡metros entrenables:** 265,221
   - **RegularizaciÃ³n:** Ninguna
   - **Test Accuracy:** 98%

2. **VersiÃ³n 2A (Extendida sin regularizaciÃ³n):**
   - Linear(512 â†’ 256) â†’ ReLU â†’ Linear(256 â†’ 128) â†’ ReLU â†’ Linear(128 â†’ 5)
   - **ParÃ¡metros entrenables:** 427,525
   - **RegularizaciÃ³n:** Ninguna
   - **Test Accuracy:** 92%

3. **VersiÃ³n 2B (Con regularizaciÃ³n):**
   - Linear(512 â†’ 256) â†’ BatchNorm1d â†’ Dropout(0.3) â†’ ReLU â†’ Linear(256 â†’ 128) â†’ BatchNorm1d â†’ Dropout(0.3) â†’ ReLU â†’ Linear(128 â†’ 5)
   - **ParÃ¡metros entrenables:** 428,293
   - **RegularizaciÃ³n:** BatchNorm + Dropout (p=0.3)
   - **Test Accuracy:** 94%

**ConfiguraciÃ³n de Entrenamiento:**
- **Optimizer:** Adam (lr=0.001)
- **Loss Function:** CrossEntropyLoss
- **Batch Size:** 32
- **Early Stopping:** Patience = 7
- **Data Augmentation:** Flip horizontal, rotaciÃ³n, normalizaciÃ³n ImageNet

---

## ğŸ“– Referencias

- [SqueezeNet Paper](https://arxiv.org/abs/1602.07360)
- [PyTorch Transfer Learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)
- [SqueezeNet Documentation](https://pytorch.org/vision/stable/models/squeezenet.html)

---

**Curso INFO1185 - 2025**
